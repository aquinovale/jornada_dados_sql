No nÃ­vel **Especialista**, vamos focar no **INSERT em cenÃ¡rios distribuÃ­dos, paralelismo, tuning avanÃ§ado e estratÃ©gias em ambientes de alta disponibilidade**. Aqui o objetivo Ã© mostrar como um **Engenheiro de Dados** lida com inserÃ§Ãµes em escala de produÃ§Ã£o, Big Data e clusters distribuÃ­dos.

---

# Aula 06 - InserÃ§Ã£o de Dados (INSERT) - Especialista

JÃ¡ vimos como inserir dados em cenÃ¡rios bÃ¡sicos, intermediÃ¡rios e avanÃ§ados.  
Agora, no nÃ­vel **Especialista**, vamos explorar **estratÃ©gias de inserÃ§Ã£o em larga escala**, pensando em **alta performance, distribuiÃ§Ã£o e arquiteturas de Big Data**.

---

## âš¡ InserÃ§Ã£o paralela

Em tabelas muito grandes, um Ãºnico `INSERT` pode se tornar gargalo.  
Alguns SGBDs e ferramentas permitem **inserÃ§Ãµes paralelas**:

- **PostgreSQL** â†’ paralelismo pode ser alcanÃ§ado via **particionamento** e mÃºltiplos processos `COPY` em paralelo.  
- **Spark + JDBC** â†’ escreve em paralelo em mÃºltiplas partiÃ§Ãµes.  

Exemplo com Spark:

```python
df.write \
  .format("jdbc") \
  .option("url", "jdbc:postgresql://localhost:5432/liga_sudoers") \
  .option("dbtable", "clientes") \
  .option("user", "sudoers") \
  .option("password", "password") \
  .mode("append") \
  .save()
```

ğŸ‘‰ Aqui cada partiÃ§Ã£o do DataFrame gera inserts em paralelo.  

---

## ğŸ—‚ï¸ InserÃ§Ã£o em tabelas particionadas

Quando lidamos com milhÃµes/bilhÃµes de registros, o ideal Ã© **particionar** dados por chave lÃ³gica (ex: data).  

```sql
CREATE TABLE vendas_2025 PARTITION OF vendas
FOR VALUES FROM ('2025-01-01') TO ('2025-12-31');
```

Depois, o `INSERT` Ã© direcionado automaticamente para a partiÃ§Ã£o correta:

```sql
INSERT INTO vendas (data_venda, cliente_id, valor)
VALUES ('2025-03-01', 101, 500.00);
```

ğŸ‘‰ Isso melhora performance de inserÃ§Ã£o e consultas.  

---

## ğŸ—ï¸ InserÃ§Ã£o em arquiteturas distribuÃ­das

Em cenÃ¡rios de **Big Data**, o `INSERT` pode nÃ£o ser a melhor opÃ§Ã£o.  
Usamos **frameworks distribuÃ­dos** e **data lakes** para ingestÃ£o massiva:

- **Hive / Spark SQL** â†’ `INSERT INTO tabela SELECT ...`  
- **Delta Lake** â†’ inserÃ§Ãµes otimizadas com ACID.  
- **Kafka Connect** â†’ ingestÃ£o contÃ­nua em SGBDs.  

Exemplo Spark SQL em Delta Lake:

```sql
INSERT INTO delta.`/mnt/datalake/vendas`
SELECT * FROM staging_vendas WHERE ano = 2025;
```

---

## ğŸ”„ EstratÃ©gias de ingestÃ£o

Existem diferentes estratÃ©gias para inserir dados em produÃ§Ã£o:

1. **Batch Ingestion (lotes)**  
   - Grandes volumes em horÃ¡rios definidos.  
   - Exemplo: carga diÃ¡ria com `COPY` ou Spark.

2. **Streaming Ingestion (tempo real)**  
   - Dados chegando continuamente.  
   - Exemplo: Kafka â†’ Spark Structured Streaming â†’ PostgreSQL.

3. **Micro-batching**  
   - Combina batch + streaming.  
   - Exemplo: processa dados a cada 1 minuto em mini-lotes.  

---

## ğŸ¯ Tuning de performance em Inserts

- **Batch size** â†’ evite inserir linha a linha, use lotes (`1000+` registros por vez).  
- **Checkpoint / commit interval** â†’ em streaming, define a frequÃªncia de escrita.  
- **Write Ahead Logging (WAL)** â†’ configure corretamente no PostgreSQL para balancear performance e durabilidade.  
- **Ãndices** â†’ em cargas massivas, considere desabilitar/recriar Ã­ndices apÃ³s a inserÃ§Ã£o.  

---

## ğŸ›¡ï¸ Alta disponibilidade

Em sistemas crÃ­ticos, inserÃ§Ãµes precisam garantir **consistÃªncia e durabilidade**:

- **ReplicaÃ§Ã£o sÃ­ncrona** â†’ dados confirmados apenas apÃ³s escrita em rÃ©plica.  
- **Sharding** â†’ divide dados entre mÃºltiplos nÃ³s para distribuir carga.  
- **Failover automÃ¡tico** â†’ garante que inserts nÃ£o parem em caso de queda do nÃ³ principal.  

---

## ğŸ“Œ Exemplo de ingestÃ£o distribuÃ­da (Kafka â†’ PostgreSQL)

```yaml
# ConfiguraÃ§Ã£o simplificada Kafka Connect
name=clientes-sink
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
tasks.max=4
connection.url=jdbc:postgresql://db:5432/liga_sudoers
connection.user=sudoers
connection.password=password
topics=clientes_topic
insert.mode=insert
batch.size=1000
```

ğŸ‘‰ Aqui, dados chegam via **Kafka** e sÃ£o gravados no PostgreSQL em paralelo com **4 tasks**.  

---

## âš ï¸ Boas prÃ¡ticas de especialista

- Use **particionamento** para dados grandes.  
- Prefira **inserÃ§Ãµes em lote** ao invÃ©s de linha a linha.  
- Em pipelines crÃ­ticos, implemente **idempotÃªncia** (evitar duplicatas).  
- Monitore mÃ©tricas de ingestÃ£o (latÃªncia, throughput, locks).  
- Avalie se o banco relacional Ã© a melhor escolha para o volume â€” em muitos casos, Ã© melhor usar **Data Lake** + **ETL**.  

---

ğŸ“º **VÃ­deo complementar:**  
[Aula 06 â€“ Inserindo dados no SQL](https://www.youtube.com/watch?v=Hj2rkoiW8WY&list=PLD3-a_5KsN3nuXukrq8kCYtxnZR4FD2nJ&index=16)

